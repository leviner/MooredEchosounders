{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compass Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from evFileProcessing import evFuncs # ev COM functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCompassPMEL(files, mooring, start):\n",
    "    dir = []\n",
    "    temp = []\n",
    "    time = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            dfCompass=pd.read_csv(file, header = None)\n",
    "            for dat in dfCompass[1]:\n",
    "                dir.append(float(dat.split('P')[0][2:]))\n",
    "                temp.append(float(dat.split('-')[-1][:-3]))\n",
    "            for t in dfCompass[0]:\n",
    "                time.append(t)\n",
    "        except:\n",
    "            continue\n",
    "    corrTime = [start+(x- pd.to_datetime(time[5])) for x in  pd.to_datetime(time[5:min(len(time), len(dir))])]\n",
    "    df = pd.DataFrame({'Datetime':corrTime,'Dir_'+str(mooring):dir[5:min(len(time), len(dir))]})\n",
    "    df = df.set_index('Datetime')\n",
    "    return df\n",
    "    return time, dir\n",
    "\n",
    "def readCompassAaronia(file, mooring):\n",
    "    df = pd.read_csv(file)\n",
    "    df['Datetime'] = pd.to_datetime(df['date'] + ' ' + df['time(local time)'])\n",
    "    df = df[['Datetime','compass (deg)']]\n",
    "    df = df.rename(columns={'compass (deg)':'Dir_'+str(mooring)})\n",
    "    df = df.set_index('Datetime')\n",
    "    return df\n",
    "\n",
    "def readCompassOpenTag(files, mooring):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "        dfA = pd.concat(dfs)\n",
    "    dfA = dfA.reset_index()\n",
    "    return dfA\n",
    "\n",
    "dfD1Y1C1 = readCompassPMEL(glob('../data/2018/DAFT1/Compass/PMEL/SERIAL/*.txt'), 1, datetime.datetime(2017,8,6,17,0,0))\n",
    "dfD1Y1C2 = readCompassOpenTag(glob('../data/2018/DAFT1/Compass/OpenTag/*.csv'), 1)\n",
    "dfD2Y1C1 = readCompassPMEL(glob('../data/2018/DAFT2/Compass/PMEL/SERIAL/*.txt'), 2, datetime.datetime(2017,8,8,6,40,0))\n",
    "dfD1Y2C1 = readCompassAaronia('../data/2019//DAFT1/Compass/Aaronia/DSFT1Converted_Formatted.csv',1)\n",
    "dfD2Y2C1 = readCompassPMEL(glob('../data/2019//DAFT2/Compass/PMEL/SERIAL/*.txt'), 2, datetime.datetime(2018,8,12,16,20,0))\n",
    "dfD3Y2C1 = readCompassPMEL(glob('../data/2019//DAFT3/Compass/PMEL/SERIAL/*.txt'), 3, datetime.datetime(2018,8,14,19,30,0))\n",
    "\n",
    "ds = [dfD1Y1C1,dfD1Y2C1,dfD2Y1C1,dfD2Y2C1,dfD3Y2C1]\n",
    "fnames = ['C11_2017-2018_CompassHeading.csv','C11_2018-2019_CompassHeading.csv',\n",
    " 'C1_2017-2018_CompassHeading.csv','C1_2018-2019_CompassHeading.csv',\n",
    " 'C4_2018-2019_CompassHeading.csv']\n",
    "magDec =  [9.6, 10.3, 11.6,12.2,13.4]\n",
    "ct = 0\n",
    "for d in ds:\n",
    "    d = d.rename(columns ={d.columns[0]:'Degrees'})\n",
    "    d['Magnetic Declination'] = magDec[ct]\n",
    "    d.to_csv(fnames[ct])\n",
    "    ct+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mooring Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This builds out the axiom csv files\n",
    "fnames = ['C11_2017-2018_WBAT','C11_2018-2019_WBAT',\n",
    "             'C1_2017-2018_WBAT','C1_2018-2019_WBAT',\n",
    "             'C4_2018-2019_WBAT']\n",
    "deployments = [['DAFT1','2018'],['DAFT1','2019'],['DAFT2','2018'],['DAFT2','2019'],['DAFT3','2019']]\n",
    "ct =0\n",
    "\n",
    "for d in deployments:\n",
    "    df70 = evFuncs.evExports.readEvExports(sorted(glob('E:/MooredEchosounders/data/'+d[1]+'/EVFiles/'+d[0]+'/exports/1m/70*.csv')))\n",
    "    df38 = evFuncs.evExports.readEvExports(sorted(glob('E:/MooredEchosounders/data/'+d[1]+'/EVFiles/'+d[0]+'/exports/1m/38*.csv')))\n",
    "    df200 = evFuncs.evExports.readEvExports(sorted(glob('E:/MooredEchosounders/data/'+d[1]+'/EVFiles/'+d[0]+'/exports/1m/200*.csv')))\n",
    "   \n",
    "    df70['DateTime'] = pd.to_datetime(df70.index.map(lambda x: x.strftime('%Y-%m-%d %H')))\n",
    "    df70_clean = df70.set_index(['DateTime','layer'])\n",
    "    df38['DateTime'] = pd.to_datetime(df38.index.map(lambda x: x.strftime('%Y-%m-%d %H')))\n",
    "    df38_clean = df38.set_index(['DateTime','layer'])\n",
    "    df200['DateTime'] = pd.to_datetime(df200.index.map(lambda x: x.strftime('%Y-%m-%d %H')))\n",
    "    df200_clean = df200.set_index(['DateTime','layer'])\n",
    "    if (d[0] == 'DAFT1')&(d[1]=='2019'):\n",
    "        df38_clean['sA'] = np.nan\n",
    "    df70_clean['sA'].to_csv('AxiomData/'+fnames[ct]+'_70kHz.csv')\n",
    "    df38_clean['sA'].to_csv('AxiomData/'+fnames[ct]+'_38kHz.csv')\n",
    "    df200_clean['sA'].to_csv('AxiomData/'+fnames[ct]+'_200kHz.csv')\n",
    "    ct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be used to compare the exports and the packaged axiom datasets\n",
    "f, (ax1)= plt.subplots(1,1,figsize=(20,8),sharex=True, sharey=True,dpi=150)\n",
    "\n",
    "df1 = evFuncs.evExports.readEvExports(sorted(glob('E:/MooredEchosounders/data/2018/EVFiles/'+daft+'/exports/1m/38*.csv'))+sorted(glob('E:/MooredEchosounders/data/2019/EVFiles/'+daft+'/exports/1m/38*.csv')))\n",
    "ax1=plt.subplot(311)\n",
    "a = df1['sA'].resample('2H').sum()\n",
    "a.plot( style='.',label='Wakeups',legend=False,axes=ax1, color='tomato')\n",
    "a.resample('D').mean().plot(legend=False,label='Daily Mean', axes=ax1,linewidth=2,color='k')\n",
    "\n",
    "#ax1.set_ylim([-60,1000])\n",
    "#ax1.set_yticks([0,1000,2000,3000])\n",
    "ax1.set_xlim([pd.to_datetime('2017-8-7'),pd.to_datetime('2019-9-4')])\n",
    "ax1.grid()\n",
    "ax1.legend(['Wakeup Mean','Daily Mean'])#,loc = 'lower left')\n",
    "#ax1.set_xticklabels([])\n",
    "#ax1.xaxis.label.set_visible(False)\n",
    "plt.ylabel('70 kHz Mean Sv')\n",
    "\n",
    "df38_clean.reset_index().set_index('DateTime').resample('2H').sum().sA.plot(ax=ax1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
